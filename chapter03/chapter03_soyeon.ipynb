{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP2MD2Q78EpahwE6pvaC5qx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Chapter 3 지도 학습"],"metadata":{"id":"hBNDyHW5HCQ3"}},{"cell_type":"markdown","source":["## 3.1 지도 학습이란\n","- 지도 학습 Supervised learning\n","  - 학습 과정에서 label 혹은 target value 라는 실제 정답을 가지고 있어야 함 (라벨링 작업)\n","- 비지도 학습 Unsupervised learning\n","  - 정답 없이 문제의 패턴으로 파악하는 방법\n","\n","\n","### 기본적인 지도 학습 과정\n","- 목적은 적합한 가중치와 편향을 통해 예측을 잘 하는 좋은 모델을 만드는 것\n","- 처음에는 무작위로 가중치와 편향을 정하여 예측값 산출하며, Loss function으로 실제값과 예측값의 차이를 측정하여 다음 학습 시 차이를 더 줄이는 것이 목표 (Optimization)\n","- 손실 함수 L이 최소가 되게 하기 위한 미분 계산으로 구성된 Back-propagation으로 가중치와 편향을 업데이트하는 과정 반복\n"],"metadata":{"id":"jCloNcmcHNSI"}},{"cell_type":"code","source":["# 데이터 정의 (1)\n","train_data = ...\n","train_loader = ...\n","\n","# 반복 학습\n","for epoch in range(num_epochs): # 전체 데이터에 대한 반복 학습 (6)\n","  for inputs, labels in train_loader: # 입력값과 실제값 - Batch 데이터 나누어 학습 (2)\n","    ...\n","    optimizer.zero_grad() # 최적화 초기화\n","    outputs = model(inputs) # 예측값 산출 (2)\n","    loss = criterion(outputs, labels) # 손실 함수 계산 (3)\n","    loss.backward() # 최적화: 손실 함수 기준으로 역전파 설정 (4)\n","    optimizer.step() # 모델 가중치 업데이트 (5)\n","\n","... 중략 ..."],"metadata":{"id":"dCPl3moLZwPb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3.2 지도 학습의 종류\n","- 회귀 문제 Regression\n","  - 원하는 결괏값이 연속적인 변수인 것을 예측하는 문제\n","- 분류 문제 Classification\n","  - 원하는 결괏값이 Class로 분류되는 문제\n","  - Labeling, One-hot encoding (0 or 1)"],"metadata":{"id":"arzfPwqYbC4n"}},{"cell_type":"markdown","source":["## 3.3 데이터 세트 분할\n","- 학습 데이터 Train data\n","- 검증 데이터 Validation data\n","- 평가 데이터 Test data\n","\n","### 데이터 분할 방법\n","Random sampling, Random Stratified sampling, Cross-validation"],"metadata":{"id":"mOvCxNYPjSFw"}},{"cell_type":"code","source":["# 무작위로 섞어서 데이터 분할\n","\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","\n","X,y = np.arange(1000).reshape((100,10)), np.arange(100)\n","# 학습 데이터 70%, 평가 데이터 30%로 분할\n","X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)"],"metadata":{"id":"dkDMrqx2kXzy"},"execution_count":null,"outputs":[]}]}