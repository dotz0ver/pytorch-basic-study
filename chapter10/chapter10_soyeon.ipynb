{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMNDFa/ANGaO4dwmH7Fz76V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Chapter 10 시각화"],"metadata":{"id":"mKta3zHTYB6c"}},{"cell_type":"markdown","source":["## 10.1 설명 가능한 인공지능 Explainable AI, XAI"],"metadata":{"id":"8QYLVn9WYL4H"}},{"cell_type":"markdown","source":["### 10.1.1 Class Activation Map, CAM\n","- 이미지 분류 문제에서 이미지 내에서 어느 영역을 보고 클래스 분류를 결정했는지를 설명하는 시각화 방법\n","- 합성곱 신경망의 마지막 층에서 나온 피쳐맵과 분류기의 가중치를 이용해 영역을 찾아 내는 방식\n","- 합성곱 신경망의 마지막 층에서 나온 피쳐맵을 분류기에 넣기 위해 일렬로 펴는 Flatten을 해주는데 이때 객체 위치에 대한 정보가 소실되므로 CAM을 사용하기 위해선 합성곱 신경망의 마지막 층에서의 각각의 피쳐맵의 평균값을 사용하는 Gloabl Average Pooling, GAP을 사용"],"metadata":{"id":"K9ciSr46Ybph"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"iho8tonoX7sb","executionInfo":{"status":"ok","timestamp":1706804467594,"user_tz":-540,"elapsed":5636,"user":{"displayName":"문소연","userId":"00452830055130923194"}}},"outputs":[],"source":["# 라이브러리 불러오기\n","# CIFAR10 이미지보다 사이즈가 큰 STL10 데이터를 사용함. CAM 가독성을 확보하기 위해 128x128로 늘림\n","# 비행기, 새, 자동차, 고양이, 사슴, 개, 말, 원숭이, 배, 트럭 클래스\n","\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import cv2\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import torch.optim as optim"]},{"cell_type":"code","source":["# 데이터 불러오기\n","\n","transform = transforms.Compose([transforms.Resize(128), transforms.ToTensor()])\n","trainset = torchvision.datasets.STL10(root='./data',split='train',download=True,transform=transform) # 96x96\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=40, shuffle=True)\n","testset = torchvision.datasets.STL10(root='./data',split='test',download=True,transform=transform) # 96x96\n","testloader = torch.utils.data.DataLoader(testset, batch_size=40, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFRP2tP6bK7O","executionInfo":{"status":"ok","timestamp":1706804752371,"user_tz":-540,"elapsed":284781,"user":{"displayName":"문소연","userId":"00452830055130923194"}},"outputId":"2f58112d-75d9-4ab7-92f8-0504f692764f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./data/stl10_binary.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2640397119/2640397119 [03:50<00:00, 11460024.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/stl10_binary.tar.gz to ./data\n","Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# 모델 불러오기\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = torchvision.models.resnet18(pretrained=True)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs,10)\n","model = model.to(device)\n","model.load_state_dict(torch.load('./models/stl10_resnet18.pth'))"],"metadata":{"id":"nWGq-8YUhACs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 정확도 확인하기\n","# 학습 정확도가 99%, 평가 정확도가 86%인 모델을 이용하여 CAM 결과 산출\n","\n","def acc(dataloader):\n","  correct = 0\n","  total = 0\n","  model.eval()\n","  with torch.no_grad():\n","    for data in dataloader:\n","      images, labels = data[0].to(device), data[1].to(device)\n","      outputs = model(images)\n","      _,predicted = torch.max(outputs.detach(),1)\n","      total += labels.size(0)\n","      correct += (predicted == labels).sum().item()\n","  print('Accuracy: %d %%' % (100 * correct / total))\n","acc(trainloader)\n","acc(testloader)"],"metadata":{"id":"L0m5HAFhe4By"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CAM 구축하기\n","\n","activation = {}\n","# 모델의 특정 레이어에서의 피쳐맵을 추출할 수 있도록 도와주는 역할\n","def get_activation(name):\n","  def hook(model,input,output):\n","    activation[name] = output.detach()\n","  return hook"],"metadata":{"id":"MgHarQeihBUw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cam(dataset,img_sample,img_size): # 데이터셋, 이미지 번호, 사이즈\n","  model.eval()\n","  with torch.no_grad():\n","    # ResNet18의 마지막 합성곱 층의 이름은 model.layer4[1].bn2이며, register_forward_hook을 이용하여 마지막 합성곱 층의 피쳐맵을 불러올 수 있도록 지정\n","    model.layer4[1].bn2.register_forward_hook(get_activation('final')) # 마지막 합성곱 층\n","    # CAM은 이미지를 하나씩 받아 클래스 별로 가중치와 피쳐맵을 곱하기에 이미지 하나를 불러옴\n","    data,label = dataset[img_sample]\n","    # 이미지 한 장은 3차원 이미지고, 모델의 입력 데이터는 배치사이즈를 포함하여 4차원 요구\n","    data.unsqueeze_(0) # 0번재 차원 하나 늘려줌(죽, [피쳐수,너비,높이] -> [1,피쳐수,너비,높이])\n","    # 모델의 예측값 구함\n","    output = model(data.to(device))\n","    _,prediction = torch.max(output,1)\n","    # 마지막 합성곱 층의 피쳐맵을 불러오고 분류기의 가중치 불러옴\n","    act = activation['final'].squeeze()\n","    w = model.fc.weight\n","    # 피쳐맵과 해당 예측 클래스와 관련된 가중치를 곱하여 누적\n","    for idx in range(act.size(0)):\n","      if idx == 0:\n","        tmp = act[idx] * w[prediction.item()][idx]\n","      else:\n","        tmp += act[idx] * w[prediction.item()][idx]\n","    # 계산된 CAM 이미지를 0~255 값으로 변환\n","    normalized_cam = tmp.cpu().numpy()\n","    normalized_cam = (normalized_cam - np.min(normalized_cam)) / (np.max(normalized_cam) - np.min(normalized_cam))\n","    # 원본 이미지 불러옴\n","    original_img = np.uint8(data[0][0] / 2 + 0.5) * 255\n","    # CAM 이미지를 원본 이미지와 동일한 크기로 리사이즈\n","    cam_img = cv2.resize(np.uint8(normalized_cam * 255), dsize=(img_size,img_size))\n","  return cam_img, original_img, prediction, label"],"metadata":{"id":"1k2Rn-_9hUdh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# CAM 결과 산출 함수 정의하기\n","\n","def plot_cam(dataset,img_size,start): # 데이터셋, 이미지 크기, 이미지 시작번호\n","  end = start + 20 # 시작 번호로부터 20장의 CAM 출력\n","  # 표 및 부분 그래프에 대한 크기와 설정 및 공백 조절\n","  fig, axs = plt.subplots(2, (end - start + 1) // 2, figsize=(20,4))\n","  fig.subplots_adjust(hspace=.01, wspace=.01)\n","  axs = axs.ravel()\n","  # 클래스 명 정의\n","  cls = ['airplane','bird','car','cat','deer','dog','horse','monkey','ship','truck']\n","  # 이미지를 하나씩 불러옴\n","  for i in range(start, end):\n","    cam_img, original_img, prediction, label = cam(dataset,i,img_size)\n","    # 정확한 예측은 라벨의 배경이 흰색, 잘못된 예측에 대해서는 빨간색으로 지정\n","    if prediction == label:\n","      color = 'white'\n","    else:\n","      color = 'red'\n","    # 원본 이미지는 흑백으로 바꾸고 CAM 결과는 jet을 이용해 히트맵으로 표현 (alpha: 히트맵 밝기값)\n","    axs[i - start].imshow(original_img, cmap='gray')\n","    axs[i - start].imshow(cam_img, cmap='jet', alpha=.4)\n","    # 라벨 주석 달아주고, 좌표 표시 모두 없앰\n","    axs[i - start].text(5, 5, cls[prediction], bbox={'facecolor':color,'pad':5})\n","    axs[i - start].axis('off')\n","  plt.show()"],"metadata":{"id":"0xVQo-5ckRZr","executionInfo":{"status":"ok","timestamp":1706806252273,"user_tz":-540,"elapsed":47,"user":{"displayName":"문소연","userId":"00452830055130923194"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# CAM 결과 산출\n","# 히트맵에서 빨간 부분은 결과에 크게 영향을 미쳤다는 의미, 파란색에 가까울수록 예측이 덜 영향 주는 영역\n","\n","plot_cam(trainset, 128, 10)\n","plot_cam(testset, 128, 10)"],"metadata":{"id":"_aceNwS2ntit"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 10.2 차원 축소 기법\n","- 우리가 시각적으로 표현할 수 있는 차원은 3차원 이하이므로 고차원의 벡터들을 3차원 이하의 저차원으로 바꿔야 함ㄴ"],"metadata":{"id":"glWz-vBJn-Gu"}},{"cell_type":"markdown","source":["### 10.2.1 t-distributed Stochastic Neighbor Embedding\n","- 합성곱 신경망을 거쳐 나온 고차원의 피쳐맵을 분석하기 위해 사용되는 차원 축소 기법 중 하나"],"metadata":{"id":"WuzwEehnoKMU"}},{"cell_type":"code","source":["# 라이브러리 불러오기\n","\n","from sklearn.manifold import TSNE\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","import torch.nn as nn"],"metadata":{"id":"gNfMwhI_oUaL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 불러오기\n","\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n","testset = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n","testloader = torch.utils.data.DataLoader(testset,batch_size=16)"],"metadata":{"id":"AOMnaEloom1k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 모델 불러오기\n","# 일반적으로 마지막 합성곱 층에서 추출된 피쳐맵을 가지고 분포를 그림\n","# hook을 사용하여 피쳐맵을 추출할 수도 있지만 코드 간소화를 위해 분류기 자체를 항등 함수 f(x)=x로 변경하여 모델에서의 출력값을 피쳐맵으로 뽑아낼 수 있음\n","\n","# 항등 함수\n","class Identify(nn.Module):\n","  def __init__(self):\n","    super(Identify,self).__init__()\n","  def forward(self,x):\n","    return x\n","\n","model = torchvision.models.resnet18(pretrained=False)\n","model.conv1 = nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1)\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs,10)\n","model = model.to(device)\n","model.load_state_dict(torch.load('./models/cifar10_resnet18.pth'))\n","model.fc = Identify()"],"metadata":{"id":"0Hx6BUfvpBcL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 피쳐맵과 예측값 저장하기\n","\n","actual = []\n","deep_features = []\n","model.eval()\n","with torch.no_grad():\n","  for data in testloader:\n","    images, labels = data[0].to(device), data[1].to(device)\n","    # classifier를 제거했기 때문에 이전 값인 Global Average Pooling값이 features가 됨 (즉, 이미지의 피쳐 크기는 512이므로 512차원 벡터가 됨)\n","    features = model(images)\n","    deep_features += features.cpu().tolist()\n","    actual += labels.cpu().tolist()"],"metadata":{"id":"yF1rfCB7qMDw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# t-SNE 정의하기\n","\n","# n_components: 차원 축소의 차원 수. 512차원의 모든 deep_features 값들을 2차원 좌표로 축소한다는 의미\n","# 또한 t-SNE는 차원 축소 시 임의의 점을 기준으로 잡고 저차원 임베딩을 함\n","tsne = TSNE(n_components=2, random_state=0)\n","# 차원 축소 데이터 만듦. cluster는 각 이미지에 대응하는 2차원 벡터들의 모임\n","# cluster의 0열은 x좌표, 1열은 y좌표가 됨\n","cluster = np.array(tsne.fit_transform(np.array(deep_features)))\n","actual = np.array(actual)"],"metadata":{"id":"Lq-HAPOmrBn1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# t-SNE 그래프 그리기\n","\n","plt.figure(figsize=(10,10))\n","cifar = ['plane','car','bird','cat','deer','dog','horse','monkey','ship','truck']\n","# 각 클래스를 하나씩 불러와서 scaatter 함수로 좌표를 찍어줌\n","# 실제값 actual을 0~9 차례대로 받아 for문이 한 번 돌 때마다 클래스 하나에 대한 데이터 그림\n","for i, label in zip(range(10), cifar):\n","  idx = np.where(actual == i)\n","  # cluster 좌표를 넣어주고 legend를 위해 label을 넣어줌\n","  plt.scatter(cluster[idx,0],cluster[idx,1],marker='.',label=label)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"okI9SySCr1Rj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["10.2.2 주성분 분석 Principal Component Analysis, PCA\n","- 대표적 차원 축소기법 중 하나\n","- t-SNE의 차원 축소는 PCA보다 본래 특성을 덜 훼손하지만 차원 축소된 값을 활용하는데 한계가 있음. 하지만 PCA는 데이터의 고윳값을 이용해 분석하기에 클러스터링 및 데이터 분석에 활용도가 큼"],"metadata":{"id":"g3nwfvDKsby-"}},{"cell_type":"code","source":["# PCA 정의하기\n","\n","from sklearn.decomposition import PCA\n","pca = PCA(n_components=2)\n","cluster = np.array(pca.fit_transform(np.array(deep_features)))\n","print(pca.explained_variance_ratio_)"],"metadata":{"id":"ej8Ki4rFs-cP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# PCA 그래프 그리기\n","\n","plt.figure(figsize=(10,10))\n","\n","for i, label in zip(range(10), cifar):\n","  idx = np.where(actual == i)\n","  plt.scatter(cluster[idx,0],cluster[idx,1],marker='.',label=label)\n","plt.legend()\n","plt.show()"],"metadata":{"id":"9IfAGqOdtBBz"},"execution_count":null,"outputs":[]}]}